# ğŸ“‰ Customer Churn Prediction (Telco Dataset)

A machine learning project using the **Telco Customer Churn** dataset to predict which customers are likely to leave.  
This repo demonstrates **end-to-end churn modelling** with business framing:  
ETL â†’ Feature Engineering â†’ Model Training â†’ Scoring â†’ BI integration (Power BI / Tableau).

---

## ğŸš€ What This Project Does

- ğŸ“¥ **Loads & cleans** the Telco dataset (demographics, services, billing, churn flag).  
- ğŸ§¹ **Prepares features** (numeric scaling, categorical encoding, leakage control).  
- ğŸ¤– **Trains models**: Logistic Regression & Random Forest.  
- ğŸ“Š **Evaluates** with ROC-AUC, PR-AUC, classification report.  
- ğŸ† **Saves the best model** (by ROC-AUC).  
- ğŸ”® **Scores all customers** with churn probabilities â†’ exports to CSV for BI dashboards.  
- ğŸ“ˆ **Supports business actions** like targeting high-risk customers with retention campaigns.  

---

## ğŸ§° Tech Stack

- **Python**: `pandas`, `numpy`, `scikit-learn`, `joblib`  
- **Visualisation**: Power BI / Tableau / Excel (via CSV exports)  
- **ETL**: Clean + preprocess pipeline  
- **ML**: Logistic Regression, Random Forest  

---

## ğŸ“ Repository Structure

```
telco-churn-ml/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                           # Original Telco dataset (CSV)
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ best_model.joblib          # Best saved model (logit or RF)
â”‚   â””â”€â”€ bi_exports/
â”‚       â”œâ”€â”€ telco_clean.csv            # Cleaned dataset
â”‚       â””â”€â”€ churn_scored.csv           # Full dataset with churn predictions
â””â”€â”€ scripts/
    â”œâ”€â”€ ingest_clean.py                # Clean and preprocess Telco dataset
    â””â”€â”€ train_model.py                 # Train, evaluate, save model + score full dataset
```

---

## â–¶ï¸ How to Run

### 1. Create a virtual environment

**Windows PowerShell**
```bash
python -m venv venv
venv\Scripts\Activate.ps1
```

**macOS/Linux**
```bash
python -m venv venv
source venv/bin/activate
```

---

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

---

### 3. Ingest & Clean Data

Prepare the dataset for ML:  
```bash
python scripts/ingest_clean.py
```

Outputs:  
- `outputs/bi_exports/telco_clean.csv`

---

### 4. Train & Score Models

Run training + scoring:  
```bash
python scripts/train_model.py
```

Outputs:  
- `outputs/models/best_model.joblib`  
- `outputs/bi_exports/churn_scored.csv`  

---

### 5. Sanity Checks

```bash
# Does model file exist?
dir outputs/models/best_model.joblib

# Peek at churn_scored.csv
python - <<'PY'
import pandas as pd
d = pd.read_csv('outputs/bi_exports/churn_scored.csv')
print(d.head())
print('Rows:', len(d), '| Pred churners:', d['pred_label'].sum())
print('Proba range:', float(d['pred_proba'].min()), 'â†’', float(d['pred_proba'].max()))
PY
```

---

## ğŸ“Š Example BI Dashboard

Use `outputs/bi_exports/churn_scored.csv` in **Power BI / Tableau / Excel**:  
- KPI Cards: Predicted churners, churn rate, retention rate.  
- Bar chart: Churn rate by Contract type, Internet service, Payment method.  
- Matrix: Churn by Gender Ã— Senior Citizen Ã— Tenure buckets.  
- Slicers: contract type, payment method, region.  

---

## ğŸ¯ Why This Project Matters

- **Business framing**: ties churn prediction to retention campaigns and revenue impact.  
- **ETL â†’ ML â†’ BI**: full data pipeline that mirrors real data science workflows.  
- **Explains trade-offs**: precision vs recall, targeting the right customers.  
- **Recruiter appeal**: interpretable logistic regression + robust random forest baseline.  

---

## ğŸ”’ Notes

- The dataset comes from the [Telco Customer Churn dataset on Kaggle](https://www.kaggle.com/blastchar/telco-customer-churn).  
- `.env` is not needed for this project.  
- `outputs/` can be safely `.gitignore`d except for sample exports.  

---

## ğŸ“„ Licence

MIT Licence â€“ free to use and adapt.  
